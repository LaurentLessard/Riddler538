{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Scrabble superstring**\n",
    "## [Riddler Classic, Jun. 28, 2019](https://fivethirtyeight.com/features/whats-your-best-scrabble-string/)\n",
    "\n",
    "### solution by [Laurent Lessard](https://laurentlessard.com)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some preliminaries\n",
    "\n",
    "Here I tabulate the tile distribution and collect the list of admissible words. I used the [ENABLE word list](https://norvig.com/ngrams/enable1.txt), as instructed in the problem statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from gurobipy import *\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word list contains 172820 words.\n"
     ]
    }
   ],
   "source": [
    "# Load the list of legal words. There are N words total\n",
    "f = open(\"enable1.txt\",\"r\")\n",
    "WORDLIST = [ w[:-1] for w  in f ]\n",
    "N = len(WORDLIST)\n",
    "print('The word list contains', N, 'words.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of all the letter tiles\n",
    "TILES = 12*'e' + 9*'a' + 9*'i' + 8*'o' + 6*'n' + 6*'r' + 6*'t' + 4*'l' \\\n",
    "       + 4*'s' + 4*'u' + 4*'d' + 3*'g' + 2*'b' + 2*'c' + 2*'m' + 2*'p' \\\n",
    "       + 2*'f' + 2*'h' + 2*'v' + 2*'w' + 2*'y' + 'kjxqz' + 2*'_'\n",
    "\n",
    "# All the letters in the world\n",
    "ALPHABET = 'abcdefghijklmnopqrstuvwxyz'\n",
    "L = len(ALPHABET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much is each letter worth, and how much is a word worth?\n",
    "# an unknown blank is _, and a known blanks are in uppercase\n",
    "scoredic = dict()\n",
    "for lett in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ_':\n",
    "    scoredic[lett] = 0\n",
    "for lett in 'eaionrtlsu':\n",
    "    scoredic[lett] = 1\n",
    "for lett in 'dg':\n",
    "    scoredic[lett] = 2\n",
    "for lett in 'bcmp':\n",
    "    scoredic[lett] = 3\n",
    "for lett in 'fhvwy':\n",
    "    scoredic[lett] = 4\n",
    "for lett in 'k':\n",
    "    scoredic[lett] = 5\n",
    "for lett in 'jx':\n",
    "    scoredic[lett] = 8\n",
    "for lett in 'qz':\n",
    "    scoredic[lett] = 10\n",
    "    \n",
    "@lru_cache(maxsize=None)\n",
    "def wordscore(word):\n",
    "    \"\"\"\n",
    "    Evaluate the Scrabble score of a given word\n",
    "    \"\"\"\n",
    "    return sum( scoredic[lett] for lett in word )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cull_wordlist( wordlist, tiles_available ):\n",
    "    \"\"\"\n",
    "    return the subset of a wordlist (list of strings) that can be made\n",
    "    using tiles from tiles_available (a string, can include blanks _)\n",
    "    \"\"\"\n",
    "    available_letter_counts = np.array([ tiles_available.count(lett) for lett in ALPHABET ])\n",
    "    available_blank_count = tiles_available.count('_')\n",
    "    culled_wordlist = []\n",
    "    \n",
    "    word_letter_counts = np.array([ [word.count(lett) for lett in ALPHABET] for word in wordlist ])\n",
    "    for (ix,lettcount) in enumerate(word_letter_counts):\n",
    "        if sum( [n for n in available_letter_counts-lettcount if n < 0] ) + available_blank_count >= 0:\n",
    "            culled_wordlist.append( wordlist[ix] )\n",
    "            \n",
    "    return culled_wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findall(s, p):\n",
    "    \"\"\"\n",
    "    Yields all the positions of\n",
    "    the pattern p in the string s.\n",
    "    \"\"\"\n",
    "    i = s.find(p)\n",
    "    while i != -1:\n",
    "        yield i\n",
    "        i = s.find(p, i+1)\n",
    "\n",
    "\n",
    "def stringscore(s, wordlist):\n",
    "    \"\"\"\n",
    "    Evaluate the total score of a superstring, looking for words in wordlist\n",
    "    Use this when the string doesn't contain any blanks ('_' or uppercase)\n",
    "    \"\"\"\n",
    "    scoretot = 0\n",
    "    for word in wordlist:\n",
    "        if word in s:\n",
    "            scoretot += wordscore(word)\n",
    "    return scoretot\n",
    "\n",
    "def stringscore_filledblanks(s, wordlist):\n",
    "    \"\"\"\n",
    "    Evaluate the total score of a superstring that contains filled blanks\n",
    "    (filled in as uppercase letter)\n",
    "    \"\"\"\n",
    "    slower = s.lower()\n",
    "    scoretot = 0\n",
    "    for word in wordlist:\n",
    "        if word in slower:\n",
    "            scoretot += max( [ wordscore(s[i:i+len(word)]) for i in findall(slower, word) ] )\n",
    "    return scoretot\n",
    "    \n",
    "def stringscore_bestblanks(s, wordlist):\n",
    "    \"\"\"\n",
    "    Evaluate the total score of a superstring that contains blanks ('_')\n",
    "    by filling in the blanks with the letter yielding the highest score\n",
    "    \"\"\"\n",
    "    if '_' not in s:\n",
    "        return stringscore_filledblanks(s, wordlist)\n",
    "    \n",
    "    locblanks = list(findall(s, '_'))\n",
    "    numblanks = len(locblanks)\n",
    "    slist = list(s)\n",
    "    scorelist = []\n",
    "    for vals in itertools.product(ALPHABET.upper(), repeat=numblanks):\n",
    "        for (ix,i) in enumerate(locblanks):\n",
    "            slist[i] = vals[ix]\n",
    "            scorelist.append( stringscore_filledblanks(''.join(slist), wordlist) )\n",
    "    return max(scorelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dotheymatch(w1,w2,lett):\n",
    "    \"\"\"\n",
    "    Returns True if words w1 and w2 can both match while sharing letter lett.\n",
    "    We assume w1 and w2 each contain letter lett exactly once.\n",
    "    \"\"\"\n",
    "    i1 = w1.find(lett)\n",
    "    i2 = w2.find(lett)\n",
    "    match_right = (w1[i1:] in w2) or (w2[i2:] in w1)\n",
    "    match_left  = (w1[:i1+1] in w2) or (w2[:i2+1] in w1)\n",
    "    return match_right and match_left\n",
    "\n",
    "def getlettwords(wordlist, lett):\n",
    "    \"\"\"\n",
    "    filter a wordlist by those containing a particular letter exactly once\n",
    "    \"\"\"\n",
    "    lwords = []\n",
    "    lwordscores = []\n",
    "    for w in wordlist:\n",
    "        if w.count(lett) == 1:\n",
    "            lwords.append(w)\n",
    "            lwordscores.append(wordscore(w))\n",
    "    return (lwords,lwordscores)\n",
    "\n",
    "def makegraph(lwords,lett):\n",
    "    \"\"\"\n",
    "    assume lwords is a list of words containing the letter lett exactly once.\n",
    "    create graph where each node is one of the lwords. two lwords are connected\n",
    "    by an edge if they can both simultaneously use letter lett (admissible overlap)\n",
    "    \"\"\"\n",
    "    n = len(lwords)\n",
    "    elist = [ (w1,w2) for (w1,w2) in itertools.combinations(lwords,2) if dotheymatch(w1,w2,lett) ]\n",
    "    return nx.Graph(elist)\n",
    "\n",
    "def unionize(clique,lett):\n",
    "    \"\"\"\n",
    "    take in a clique of words that all match on letter lett\n",
    "    and return the union word that contains all words in the clique\n",
    "    \"\"\"\n",
    "    leftwords = []\n",
    "    rightwords = []\n",
    "    for w in clique:\n",
    "        ix = w.find(lett)\n",
    "        leftwords.append( w[:ix] )\n",
    "        rightwords.append( w[ix+1:] )\n",
    "    leftwords.sort(key=len)\n",
    "    rightwords.sort(key=len)\n",
    "    return leftwords[-1] + lett + rightwords[-1]\n",
    "\n",
    "def getbestcliques(G,lett):\n",
    "    \"\"\"\n",
    "    given a graph created using makegraph and the letter lett,\n",
    "    for each maximal clique, return (each item is a list)\n",
    "    ( clique score, list of clique words, unionized clique word )\n",
    "    \"\"\"\n",
    "    cliques = nx.find_cliques(G)\n",
    "    cliquescores = []\n",
    "    cliquewords = []\n",
    "    cliqueunion = []\n",
    "    for c in cliques:\n",
    "        cliquewords.append( c )\n",
    "        cliquescores.append( sum( [wordscore(w) for w in c] ) )\n",
    "        cliqueunion.append( unionize(c,lett) )\n",
    "    isrt = np.argsort(cliquescores)[::-1]\n",
    "    return [ cliquescores[i] for i in isrt ], [ cliquewords[i] for i in isrt ], [ cliqueunion[i] for i in isrt ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majorize_test( list1, list2 ):\n",
    "    \"\"\"\n",
    "    returns True if every element of list 1 is >= the corresp elem of list2\n",
    "    \"\"\"\n",
    "    return all( [ list1[i] >= list2[i] for i in range(len(list1)) ] )\n",
    "\n",
    "def eliminate_letter( tiles, wordlist, lett, k=1 ):\n",
    "    \"\"\"\n",
    "    Find the k best word clusters that use the letter lett exactly once\n",
    "    given the tiles and wordlist available. Return:\n",
    "    (winning cluster, cluster score, remaining tiles)\n",
    "    \"\"\"\n",
    "    (words,scores) = getlettwords(wordlist,lett)\n",
    "    print(len(words), lett, 'words')\n",
    "    G = makegraph(words,lett)\n",
    "    scores,_,unions = getbestcliques(G,lett)\n",
    "    \n",
    "    # only keep the ones we can actually make with the letters we have:\n",
    "    tot_lettercount = np.array( [tiles.count(lett) for lett in ALPHABET] )\n",
    "    lettercount     = np.array( [ [w.count(lett) for lett in ALPHABET] for w in unions ] )\n",
    "    \n",
    "    winning_clusters = []\n",
    "    winning_scores = []\n",
    "    \n",
    "    numfound = 0\n",
    "    for i in range(len(scores)):\n",
    "        if majorize_test( tot_lettercount, lettercount[i] ):\n",
    "            winning_clusters.append( unions[i] )\n",
    "            winning_scores.append( scores[i] )\n",
    "            numfound += 1\n",
    "            if numfound >= k:\n",
    "                break\n",
    "            \n",
    "    # assuming we will use the above list of words, what tiles + words are left over?\n",
    "    tiles_remaining = []\n",
    "    true_scores = []\n",
    "    for c in winning_clusters:\n",
    "        tmp = list(tiles)\n",
    "        for tile in c:\n",
    "            tmp.remove(tile)\n",
    "        tiles_remaining.append( ''.join(tmp) )\n",
    "        true_scores.append( stringscore_filledblanks(c,wordlist) )\n",
    "        \n",
    "    # sort winners by true score\n",
    "    isrt = np.argsort(true_scores)[::-1]\n",
    "    \n",
    "    return [ winning_clusters[i] for i in isrt ], [ true_scores[i] for i in isrt ], [ tiles_remaining[i] for i in isrt ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knapsack( clusters, scores, tiles ):\n",
    "    \"\"\"\n",
    "    given cluster and scores dicts, figure out which clusters to select\n",
    "    so that we respect the tile quotas\n",
    "    \"\"\"\n",
    "    agg_clusters = []\n",
    "    agg_scores = []\n",
    "    agg_lettcounts = np.zeros((0,L))\n",
    "    cluster_lengths = []\n",
    "\n",
    "    for key,val in clusters.items():\n",
    "        cluster_lengths = len(val)\n",
    "        agg_clusters.extend(val)\n",
    "        agg_lettcounts = np.vstack( [agg_lettcounts, np.array( [ [w.count(lett) for lett in ALPHABET] for w in val ] )] )\n",
    "\n",
    "    for key,val in scores.items():\n",
    "        agg_scores.extend(val)\n",
    " \n",
    "    tot_lettercount = np.array( [ tiles.count(lett) for lett in ALPHABET ] )\n",
    "    \n",
    "\n",
    "    m = Model(\"knapsack\")\n",
    "    m.setParam( 'OutputFlag', False )\n",
    "    m.setParam( 'PoolSearchMode', 2 )  # find the k best solutions\n",
    "    m.setParam( 'PoolSolutions', 10 )  # k; find this many solutions\n",
    "\n",
    "    M = len(agg_clusters)\n",
    "\n",
    "    # Create variables (how many of each meta-word to use).\n",
    "    w = m.addVars(M, vtype=GRB.BINARY, name=\"w\")\n",
    "\n",
    "    # total number of words used and number of each letter used\n",
    "    tot_score = quicksum(w[i]*agg_scores[i] for i in range(M))\n",
    "    \n",
    "    letters_used = [ quicksum(agg_lettcounts[i,j]*w[i] for i in range(M)) for j in range(L) ]\n",
    "    points_used = quicksum(letters_used[j]*scoredic[ALPHABET[j]] for j in range(L))\n",
    "\n",
    "    # Set objective (minimize number of words used)\n",
    "    m.setObjective( tot_score, GRB.MAXIMIZE)\n",
    "\n",
    "    # Constraint: must use as many letters as we have tiles of each sort\n",
    "    m.addConstrs(  (letters_used[j] <= tot_lettercount[j] for j in range(L) ) )\n",
    "\n",
    "    m.optimize()\n",
    "    \n",
    "    scount = m.SolCount  # number of solutions found\n",
    "    sols = []\n",
    "    for k in range(scount):\n",
    "        m.setParam( 'SolutionNumber', k )\n",
    "        sols.append( [(agg_clusters[i], agg_scores[i]) for i,v in enumerate(m.Xn) if v > 0.5] )\n",
    "    \n",
    "    return sols\n",
    "#     return [(ix,int(v.x),agg_clusters[ix], agg_scores[ix]) for ix,v in enumerate(m.getVars()) if v.x > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve hybrid TSP/Knapsack problem to find the max-scoring permutation of letters\n",
    "def full_optimize( tiles, wordlist, wordscores ):\n",
    "\n",
    "    m = Model(\"TSP/Knapsack\")\n",
    "    m.setParam( 'OutputFlag', False )\n",
    "\n",
    "    lett_present = [ lett for lett in ALPHABET if lett in tiles ]\n",
    "    lett_counts = [ tiles.count(lett) for lett in lett_present ]\n",
    "\n",
    "    p = len(tiles)          # total number of tile Positions (exclude blanks)\n",
    "    d = len(lett_present)   # number of Distinct tiles remaining\n",
    "    w = len(wordlist)       # number of Words in the list\n",
    "\n",
    "    # Z variable: permutation matrix for the letters (distinct lett x tot lett)\n",
    "    Z = m.addVars(d,p, vtype=GRB.BINARY, name=\"Z\")\n",
    "    # rows sum to number of distinct tiles of that type, columns sum to 1\n",
    "    m.addConstrs( (quicksum(Z[i,j] for i in range(d)) == 1 for j in range(p)) )\n",
    "    m.addConstrs( (quicksum(Z[i,j] for j in range(p)) == lett_counts[i] for i in range(d)) )\n",
    "\n",
    "    # P variable: true if word i is used in position j\n",
    "    # F variable: true if word i is found in the permutation at all (Fi is true if Pij >= 1 for some j)\n",
    "    P = m.addVars(w,p, vtype=GRB.BINARY, name=\"P\")\n",
    "    F = m.addVars(w, vtype=GRB.BINARY, name=\"F\")\n",
    "    m.addConstrs( (quicksum(P[k,j] for j in range(p)) >= F[k] for k in range(w)) )\n",
    "\n",
    "    # CONSTRAINT: template matching for each word\n",
    "    for k in range(w):\n",
    "        word = wordlist[k]\n",
    "        wl = len(word)\n",
    "        word_template = [ [word[jj] == lett_present[i] for jj in range(wl)] for i in range(d) ]\n",
    "        for j in range(p):\n",
    "            if j > p-wl:\n",
    "                m.addConstr( P[k,j] == 0 )\n",
    "            else:\n",
    "                m.addConstr( quicksum( Z[i,j+jj]*word_template[i][jj] for i in range(d) for jj in range(wl) ) >= wl*P[k,j] )\n",
    "\n",
    "    # total number of words used and number of each letter used\n",
    "    tot_score = quicksum( F[k] * wordscores[k] for k in range(w))\n",
    "\n",
    "    # Set objective (minimize number of words used)\n",
    "    m.setObjective( tot_score, GRB.MAXIMIZE)\n",
    "\n",
    "    m.optimize()\n",
    "    \n",
    "    Z = np.array( [ v.x for ix,v in enumerate(m.getVars()) if ix < d*p ] ).reshape((d,p))\n",
    "    winstr = ''.join( [ [lett_present[ix] for ix,z in enumerate(Z[:,j]) if z][0] for j in range(p) ] )\n",
    "    print(winstr)\n",
    "    print(m.objVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TSPsolve( C ):\n",
    "    \"\"\"\n",
    "    Solve TSP problem where C is the cost matrix\n",
    "    output is a vector u of the final node ordering. If nodes are N then final ordering is:\n",
    "    [ N[i] for i in u ]\n",
    "    Note: we do not loop back -- we solve TSP with arbitrary start/end.\n",
    "    \"\"\"\n",
    "    m = Model(\"TSP\")\n",
    "    m.setParam( 'OutputFlag', False )\n",
    "\n",
    "    # augment cost matrix by one\n",
    "    n = C.shape[0]+1\n",
    "    c = np.zeros((n,n))\n",
    "    c[1:,1:] = C\n",
    "    \n",
    "    # X variable: permutation matrix for closed path\n",
    "    X = m.addVars(n,n, vtype=GRB.BINARY, name=\"X\")\n",
    "    # enforce row and column sums are 1, no self-loops\n",
    "    m.addConstrs( (quicksum(X[i,j] for i in range(n)) == 1 for j in range(n)) )\n",
    "    m.addConstrs( (quicksum(X[i,j] for j in range(n)) == 1 for i in range(n)) )\n",
    "    m.addConstrs( (X[i,i] == 0 for i in range(n)) )\n",
    "\n",
    "    \n",
    "    # U variable: ordering\n",
    "    u = m.addVars(n, vtype=GRB.INTEGER, lb=1, ub=n, name=\"u\")\n",
    "    # Miller-Tucker-Zemlin constraint\n",
    "    m.addConstrs( ( u[i] - u[j] + n*X[i,j] <= n-1 for i in range(n) for j in range(1,n) ))\n",
    "    \n",
    "    # total score we're trying to maximize\n",
    "    tot_score = quicksum( X[i,j]*c[i,j] for i in range(n) for j in range(n) )\n",
    "    \n",
    "    # Set objective (minimize number of words used)\n",
    "    m.setObjective( tot_score, GRB.MAXIMIZE)\n",
    "\n",
    "    m.optimize()\n",
    "    \n",
    "    return np.array( [v.x for ix,v in enumerate(m.getVars()) if ix >= n*n ], int )[1:] - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestperm( wordlist ):\n",
    "\n",
    "    n = len(wordlist)\n",
    "    wordscores = [ stringscore_filledblanks(w, WORDLIST) for w in wordlist ]\n",
    "    rewardmat = np.array( [ [stringscore_filledblanks(w1 + w2, WORDLIST) for w2 in wordlist] for w1 in wordlist ])\n",
    "    u = TSPsolve(rewardmat)\n",
    "    return ''.join([ wordlist[i] for i in u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ss(string):\n",
    "    \"\"\"\n",
    "    given a string containing 6x 's', find out which two we can remove to\n",
    "    get the best score (i.e. turn them into blanks)\n",
    "    \"\"\"\n",
    "    ix = findall(string,'s')\n",
    "    newstrings = [ string[:j1] + 'S' + string[j1+1:j2] + 'S' + string[j2+1:] for (j1,j2) in itertools.combinations(ix,2) ]\n",
    "    newstrings.sort(key=lambda x: stringscore_filledblanks(x, WORDLIST), reverse=True)\n",
    "    \n",
    "    print(newstrings[0])\n",
    "    print(stringscore_filledblanks(newstrings[0], WORDLIST))\n",
    "    return(newstrings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isvalid(string):\n",
    "    \"\"\"\n",
    "    tests if a string is valid\n",
    "    \"\"\"\n",
    "    out = True\n",
    "    if len(string) > 100:\n",
    "        print(\"string too long\")\n",
    "        out = False\n",
    "\n",
    "    for lett in ALPHABET:\n",
    "        if string.count(lett) != TILES.count(lett):\n",
    "            print(\"incorrect number of\", lett)\n",
    "            out = False        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiles: saothgskvaar\n",
      "number of words: 307\n"
     ]
    }
   ],
   "source": [
    "tiles_rem = ''.join(random.sample(TILES[:-2],12))\n",
    "words_rem = cull_wordlist(WORDLIST, tiles_rem)\n",
    "scores_rem = [ wordscore(w) for w in words_rem ]\n",
    "print( \"tiles:\", tiles_rem )\n",
    "print( \"number of words:\", len(words_rem) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-88e9dae77c21>\u001b[0m in \u001b[0;36mfull_optimize\u001b[1;34m(tiles, wordlist, wordscores)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetVars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mix\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mp\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[0mwinstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlett_present\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwinstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%time full_optimize( tiles_rem, words_rem, scores_rem )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = [ 'bluejacketsowe',  'deoxidizers',  'autobiographically',  'inadequatenesses',  'preformatting',  'uninformatively',  'overshadowing']\n",
    "n = len(wordlist)\n",
    "wordscores = [ stringscore_filledblanks(w, WORDLIST) for w in wordlist ]\n",
    "rewardmat = np.array( [ [stringscore_filledblanks(w1 + w2, WORDLIST) for w2 in wordlist] for w1 in wordlist ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bluejacketsowedeoxidizersinadequatenessespreformattinguninformativelyautobiographicallyovershadowing\n",
      "1418\n"
     ]
    }
   ],
   "source": [
    "u = TSPsolve(rewardmat)\n",
    "soln = ''.join([wordlist[i] for i in u])\n",
    "print(soln)\n",
    "print(stringscore_filledblanks(soln,WORDLIST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bluejacketsowedeoxidizerSinadequatenesseSpreformattinguninformativelyautobiographicallyovershadowing\n",
      "1410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bluejacketsowedeoxidizerSinadequatenesseSpreformattinguninformativelyautobiographicallyovershadowing'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_ss(soln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qghathexif\n",
      "78.0\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%time full_optimize( tiles_rem, words_rem, scores_rem )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "propturkr\n",
      "30.0\n",
      "Wall time: 2.42 s\n"
     ]
    }
   ],
   "source": [
    "%time full_optimize( tiles_rem, words_rem, scores_rem )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vlumirit\n",
      "26.0\n",
      "Wall time: 784 ms\n"
     ]
    }
   ],
   "source": [
    "%time full_optimize( tiles_rem, words_rem, scores_rem )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cabaabc\n",
      "17.0\n"
     ]
    }
   ],
   "source": [
    "full_optimize( 'aaabbcc', ['cab','abc', 'baa'], [7,4,6] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of the best stand-alone words\n",
    "# cull the wordlist (do not use blanks)\n",
    "tiles_ss = TILES[:-2] + 'ss'\n",
    "wordlist_ss = cull_wordlist( WORDLIST, tiles_ss )\n",
    "\n",
    "scores_ss = [ stringscore(w,wordlist_ss) for w in wordlist_ss ]\n",
    "\n",
    "isrt = np.argsort(scores_ss)[::-1]\n",
    "scores_ss = [ scores_ss[i] for i in isrt ]\n",
    "wordlist_ss = [ wordlist_ss[i] for i in isrt ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2383 j words\n",
      "2504 q words\n",
      "4549 x words\n",
      "6600 z words\n",
      "11947 k words\n"
     ]
    }
   ],
   "source": [
    "# cull the wordlist (assume the blanks will be s)\n",
    "tiles = TILES[:-2] + 'ss'\n",
    "wordlist = cull_wordlist( WORDLIST, tiles )\n",
    "\n",
    "# gather the top 200 clusters from each of four highest-scoring tiles \n",
    "letts = list('jqxzk')\n",
    "\n",
    "clusters = dict()\n",
    "scores = dict()\n",
    "tremain = dict()\n",
    "\n",
    "for lett in letts:\n",
    "    (ctmp, stmp, ttmp) = eliminate_letter( tiles, wordlist, lett, k=250 )\n",
    "    clusters[lett] = ctmp\n",
    "    scores[lett] = stmp\n",
    "    tremain[lett] = ttmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters['solo'] = wordlist_ss[:2000]\n",
    "scores['solo'] = scores_ss[:2000]\n",
    "sols = knapsack( clusters, scores, tiles_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cabinetworkingsides', 264),\n",
       " ('codevelopers', 236),\n",
       " ('prequalifying', 210),\n",
       " ('emblazoners', 209),\n",
       " ('foreshadowing', 207),\n",
       " ('overtaxations', 165),\n",
       " ('methylated', 163)]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sols[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: ['cabinetworkingsides', 'codevelopers', 'prequalifying', 'emblazoners', 'foreshadowing', 'overtaxations', 'methylated']\n",
      "remaining: aaiituuuj\n",
      "score = 1454\n",
      "words: ['prequalifying', 'cabinetworkingsides', 'codevelopers', 'emblazoners', 'foreshadowing', 'overtaxations', 'methylated']\n",
      "remaining: aaiituuuj\n",
      "score = 1454\n",
      "words: ['prequalifying', 'emblazoners', 'cabinetworkingsides', 'codevelopers', 'foreshadowing', 'overtaxations', 'methylated']\n",
      "remaining: aaiituuuj\n",
      "score = 1454\n",
      "words: ['emblazoners', 'cabinetworkingsides', 'codevelopers', 'prequalifying', 'foreshadowing', 'overtaxations', 'methylated']\n",
      "remaining: aaiituuuj\n",
      "score = 1454\n",
      "words: ['thingamajigsawed', 'emblazoners', 'decarboxylated', 'codevelopers', 'afforestations', 'unthinkingly', 'previewers']\n",
      "remaining: aiiiootuuuq\n",
      "score = 1437\n",
      "words: ['thingamajigsawed', 'decarboxylated', 'emblazoners', 'codevelopers', 'afforestations', 'unthinkingly', 'previewers']\n",
      "remaining: aiiiootuuuq\n",
      "score = 1437\n",
      "words: ['thingamajigsawed', 'decarboxylated', 'codevelopers', 'emblazoners', 'afforestations', 'unthinkingly', 'previewers']\n",
      "remaining: aiiiootuuuq\n",
      "score = 1437\n",
      "words: ['thingamajigsawed', 'decarboxylated', 'codevelopers', 'emblazoners', 'afforestations', 'unthinkingly', 'previewers']\n",
      "remaining: aiiiootuuuq\n",
      "score = 1437\n",
      "words: ['prequalifying', 'cabinetworkingsides', 'codevelopers', 'emblazoners', 'foreshowing', 'overtaxations', 'methylated']\n",
      "remaining: aaaiituuudj\n",
      "score = 1430\n",
      "words: ['emblazoners', 'cabinetworkingsides', 'codevelopers', 'prequalifying', 'foreshowing', 'overtaxations', 'methylated']\n",
      "remaining: aaaiituuudj\n",
      "score = 1430\n"
     ]
    }
   ],
   "source": [
    "for sol in sols:\n",
    "    words_used = [t[0] for t in sol]\n",
    "    tiles_used = ''.join( words_used )\n",
    "\n",
    "    tmp = list(tiles_ss)\n",
    "    for tile in tiles_used:\n",
    "        tmp.remove(tile)\n",
    "    tiles_remaining = ''.join(tmp)\n",
    "\n",
    "    print(\"words:\", words_used)\n",
    "    print(\"remaining:\", tiles_remaining)\n",
    "    print(\"score =\", sum( t[1] for t in sol ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining: aaiituuuj\n",
      "score = 1454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(991, 1, 'emblazoners', 209),\n",
       " (1079, 1, 'cabinetworkingsides', 264),\n",
       " (1345, 1, 'codevelopers', 236),\n",
       " (1517, 1, 'prequalifying', 210),\n",
       " (1564, 1, 'foreshadowing', 207),\n",
       " (2949, 1, 'overtaxations', 165),\n",
       " (3011, 1, 'methylated', 163)]"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles_used = ''.join( [t[2] for t in sol] )\n",
    "\n",
    "tmp = list(tiles_ss)\n",
    "for tile in tiles_used:\n",
    "    tmp.remove(tile)\n",
    "tiles_remaining = ''.join(tmp)\n",
    "    \n",
    "print(\"remaining:\", tiles_remaining)\n",
    "print(\"score =\", sum( t[3] for t in sol ))\n",
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining: aaiituuuj\n",
      "score = 1454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1079, 1, 'cabinetworkingsides', 264),\n",
       " (1345, 1, 'codevelopers', 236),\n",
       " (1517, 1, 'prequalifying', 210),\n",
       " (1546, 1, 'emblazoners', 209),\n",
       " (1564, 1, 'foreshadowing', 207),\n",
       " (2949, 1, 'overtaxations', 165),\n",
       " (3011, 1, 'methylated', 163)]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters['solo'] = wordlist_ss[:3000]\n",
    "scores['solo'] = scores_ss[:3000]\n",
    "sol = knapsack( clusters, scores, tiles_ss)\n",
    "\n",
    "tiles_used = ''.join( [t[2] for t in sol] )\n",
    "\n",
    "tmp = list(tiles_ss)\n",
    "for tile in tiles_used:\n",
    "    tmp.remove(tile)\n",
    "tiles_remaining = ''.join(tmp)\n",
    "    \n",
    "print(\"remaining:\", tiles_remaining)\n",
    "print(\"score =\", sum( t[3] for t in sol ))\n",
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_remain = 'aaiituuuj'\n",
    "wordlist_remain = cull_wordlist( WORDLIST, tiles_remain )\n",
    "scores_remain = [ wordscore(w) for w in wordlist_remain ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jutauaiiu\n",
      "22.0\n"
     ]
    }
   ],
   "source": [
    "full_optimize( tiles_remain, wordlist_remain, scores_remain )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emblazoners',\n",
       " 'cabinetworkingsides',\n",
       " 'codevelopers',\n",
       " 'prequalifying',\n",
       " 'foreshadowing',\n",
       " 'overtaxations',\n",
       " 'methylated',\n",
       " 'jutauaiiu']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wlist = [ t[2] for t in sol ]\n",
    "wlist.append('jutauaiiu')\n",
    "wlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_used = ['thingamajigsawed', 'emblazoners', 'decarboxylated', 'codevelopers', 'afforestations', 'unthinkingly', 'previewers']\n",
    "tiles_remain = 'aiiiootuuuq'\n",
    "wordlist_remain3 = cull_wordlist( WORDLIST, tiles_remain )\n",
    "scores_remain3 = [ wordscore(w) for w in wordlist_remain3 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iquaitoouiu\n",
      "37.0\n"
     ]
    }
   ],
   "source": [
    "full_optimize( tiles_remain, wordlist_remain3, scores_remain3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unthinkinglycodevelopersemblazonersafforestationspreviewersdecarboxylatedthingamajigsawed'"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestperm(words_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490\n"
     ]
    }
   ],
   "source": [
    "s =  ['codevelopers','unthinkingly',  'emblazoners', 'afforestations','ou', 'previewers', 'qua', 'decarboxylated','o', 'thingamajigsawed','it', 'u','ii']\n",
    "stmp = ''.join(s)\n",
    "print(stringscore_filledblanks(stmp, WORDLIST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560\n"
     ]
    }
   ],
   "source": [
    "s = ['foreshadowing', 'overtaxations', 'u','methylated']\n",
    "# s = ['foreshadowing', 'u','methylated', 'overtaxations']\n",
    "stmp = ''.join(s)\n",
    "print(stringscore_filledblanks(stmp,WORDLIST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1509\n"
     ]
    }
   ],
   "source": [
    "s = [\n",
    "     'jut','emblazoners','cabinetworkingsides','i', 'codevelopers', 'u', 'prequalifying',\n",
    "     'a','foreshadowing', 'overtaxations', 'a','methylated','ui',\n",
    "    ]\n",
    "stmp = ''.join(s)\n",
    "print(stringscore_filledblanks(stmp, WORDLIST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jutemblazonerScabinetworkingsideSicodevelopersuprequalifyingaforeshadowingovertaxationsamethylatedui\n",
      "1501\n"
     ]
    }
   ],
   "source": [
    "sfinal = remove_ss(stmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isvalid(sfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codevelopersovertaxationsmethylatedcabinetworkingsideSprequalifyingforeshadowingjutauaiiuemblazonerS\n",
      "1440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'codevelopersovertaxationsmethylatedcabinetworkingsideSprequalifyingforeshadowingjutauaiiuemblazonerS'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_ss(stmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 i words\n",
      "22 g words\n",
      "25 m words\n",
      "8 f words\n",
      "10 v words\n",
      "11 w words\n",
      "17 y words\n"
     ]
    }
   ],
   "source": [
    "# cull the wordlist (do not use blanks)\n",
    "wordlist_remaining = cull_wordlist( WORDLIST, tiles_remaining )\n",
    "\n",
    "# gather the top 200 clusters from each of four highest-scoring tiles \n",
    "letts = 'igmfvwy'\n",
    "\n",
    "clusters2 = dict()\n",
    "scores2 = dict()\n",
    "tremain2 = dict()\n",
    "\n",
    "for lett in letts:\n",
    "    (ctmp, stmp, ttmp) = eliminate_letter( tiles_remaining, wordlist_remaining, lett, k=500 )\n",
    "    clusters2[lett] = ctmp\n",
    "    scores2[lett] = stmp\n",
    "    tremain2[lett] = ttmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ifv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(76, 1, 'gamayaw', 78)]"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol2 = knapsack( clusters2, scores2, tiles_remaining)\n",
    "\n",
    "tiles_used = ''.join( [t[2] for t in sol2] )\n",
    "\n",
    "tmp = list(tiles_remaining)\n",
    "for tile in tiles_used:\n",
    "    tmp.remove(tile)\n",
    "tiles_remaining2 = ''.join(tmp)\n",
    "    \n",
    "print(tiles_remaining2)\n",
    "sol2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bluejackets',\n",
       " 'autobiographically',\n",
       " 'inadequatenesses',\n",
       " 'preformatting',\n",
       " 'deoxidizers',\n",
       " 'uninformatively',\n",
       " 'overshadowing']"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t[2] for t in sol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'wover' in WORDLIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1413"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum( [t[3] for t in sol] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1417 overshadowing\n"
     ]
    }
   ],
   "source": [
    "s = 'bluejackets' + 'owe' + 'deoxidizers' + 'autobiographically' + 'inadequatenesses' + 'preformatting'  + 'uninformatively' + 'overshadowing'\n",
    "print(stringscore_filledblanks(s, WORDLIST), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1409 overshadowing\n"
     ]
    }
   ],
   "source": [
    "s = 'bluejackets' + 'ow' + 'overshadowing' + 'e' + 'deoxidizers' + 'uninformatively' + 'autobiographically' + 'inadequatenesses' + 'preformatting'\n",
    "print(stringscore_filledblanks(s, WORDLIST), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bluejacketsowedeoxidizerSautobiographicallyinadequatenesseSpreformattinguninformativelyovershadowing\n",
      "1410\n"
     ]
    }
   ],
   "source": [
    "best_str = remove_ss(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1417\n",
      "bluejacketsowedeoxidizersautobiographicallyinadequatenessespreformattinguninformativelyovershadowing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-250cfc99fc2e>\u001b[0m in \u001b[0;36mstringscore\u001b[1;34m(s, wordlist)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwordlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mscoretot\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mwordscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscoretot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "maxscore = 0\n",
    "wlist = ['bluejackets','owe','deoxidizers','autobiographically','inadequatenesses','preformatting','uninformatively','overshadowing']\n",
    "# while True:\n",
    "#     combo = ''.join(np.random.permutation(wlist))\n",
    "for wl in itertools.permutations(wlist):\n",
    "    combo = ''.join(wl)\n",
    "    score = stringscore( combo , WORDLIST )\n",
    "    if score > maxscore:\n",
    "        maxscore = score\n",
    "        print(maxscore)\n",
    "        print(combo)\n",
    "        \n",
    "        scores = [ stringscore(''.join(wl),WORDLIST) for wl in itertools.permutations(wlist) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "all_tiles = list(TILES[:-2]+'SS')\n",
    "for t in best_str:\n",
    "    all_tiles.remove(t)\n",
    "print(all_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emblazonersunorthodoxygenatedoverbejewelediprequalificationsagamaystoutpolitickingfisherSivawardenSu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1396"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s =  'emblazoners' + 'unorthodoxygenated' + 'overbejeweled' + 'i' + 'prequalifications' + 'agamayst' + 'outpolitickingfisherS' + 'i' + 'vawardenS' + 'u'\n",
    "print(s)\n",
    "stringscore_filledblanks(s, WORDLIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emblazonersunorthodoxygenatedoverbejeweledgetawaySaramidivanSoutpolitickingfishersuprequalifications\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1401"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s =  'emblazoners' + 'unorthodoxygenated' + 'overbejeweled' + 'getaway' + 'S' + 'aramidivan' + 'S' + 'outpolitickingfishers' + 'u' + 'prequalifications'\n",
    "print(s)\n",
    "stringscore_filledblanks(s, WORDLIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emblazonersunorthodoxygenatedoverbejeweledgetawaySaramidivanSoutpolitickingfishersuprequalifications\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1401"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s =  'emblazoners' + 'unorthodoxygenated' + 'overbejeweled' + 'getaway' + 'S' + 'aramidivan' + 'S' + 'outpolitickingfishers' + 'u' + 'prequalifications'\n",
    "print(s)\n",
    "stringscore_filledblanks(s, WORDLIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unorthodoxygenatedoverbejeweledgetawaySaramidivanSemblazonersoutpolitickingfishersuprequalifications\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'unorthodoxygenated' + 'overbejeweled' + 'getaway' + 'S' + 'aramidivan' + 'S' + 'emblazoners' + 'outpolitickingfishers' + 'u' + 'prequalifications'\n",
    "print(s)\n",
    "stringscore_filledblanks(s, WORDLIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLoverbejeweledunorthodoxygenationsoutpolitickingfishersiprequalifyinguavawaditamaceratedemblazoners\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1399"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'CL' + 'overbejeweledunorthodoxygenationsoutpolitickingfishersiprequalifyinguavawaditamaceratedemblazoners'\n",
    "print(s)\n",
    "stringscore_filledblanks(s, WORDLIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLoverbejeweleduprequalifyingoutpolitickingfishersunorthodoxygenationsiemblazonersavawaditamacerated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1394"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'CL' + 'overbejeweled' + 'u' + 'prequalifying' + 'outpolitickingfishers' + 'unorthodoxygenations' + 'i' + 'emblazoners'  + 'a' + 'vawadi' + 'tamacerated'\n",
    "print(s)\n",
    "stringscore_filledblanks(s, WORDLIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avawadiSCoverbejeweleduprequalifyingoutpolitickingfishersunorthodoxygenationsiemblazonerstamacerated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1398"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'a' + 'vawadi' + 'SC' + 'overbejeweled' + 'u' + 'prequalifying' + 'outpolitickingfishers' + 'unorthodoxygenations' + 'i' + 'emblazoners' + 'tamacerated'\n",
    "print(s)\n",
    "stringscore_filledblanks(s, WORDLIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eeeeeeeeeeeeaaaaaaaaaiiiiiiiiioooooooonnnnnnrrrrrrttttttllllssssuuuuddddgggbbccmmppffhhvvwwyykjxqz__\n"
     ]
    }
   ],
   "source": [
    "print(TILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoverbejeweledprequalificationsunorthodoxygenatedemblazonersoutpolitickingfisherswagamaySunivariated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1355"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'L' + 'overbejeweled' + 'prequalifications' + 'unorthodoxygenated' + 'emblazoners' + 'outpolitickingfishers' + 'wagamay' + 'S' + 'univariated' \n",
    "print(s)\n",
    "stringscore_filledblanks(s, WORDLIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fumediiteleviewingsvarajaywalkersparadichlorobenzenestunorthodoxygenatedUprequalificationsgumbootieS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1276"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'fumedii' + 'televiewing' + 'svarajaywalkers' + 'paradichlorobenzenes' + 't' + 'unorthodoxygenated' + 'U' + 'prequalifications' + 'gumbootie' + 'S'\n",
    "\n",
    "stringscore_filledblanks(s, WORDLIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'televiewing' + 'svarajaywalkers' + 'paradichlorobenzenes' + 't' + 'unorthodoxygenated' + '_' + 'prequalifications' + 'gumbootie' + '_' + 'fumedii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1274"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringscore_filledblanks('televiewingsvarajaywalkersparadichlorobenzenestunorthodoxygenatedUprequalificationsgumbootieSfumedii', WORDLIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380 j words\n",
      "971 q words\n",
      "2058 x words\n",
      "1629 z words\n",
      "790 k words\n"
     ]
    }
   ],
   "source": [
    "# cull the wordlist (do not use blanks)\n",
    "tiles = TILES[:-2]\n",
    "wordlist = cull_wordlist( WORDLIST, tiles )\n",
    "\n",
    "# gather the top cluster from each of four starting letters, proceeding recursively\n",
    "# and eliminating letters as we go\n",
    "letts = ['j','q','x','z','k']\n",
    "\n",
    "clusters = []\n",
    "scores = []\n",
    "tremain = []\n",
    "\n",
    "for lett in letts:\n",
    "    (ctmp, stmp, ttmp) = eliminate_letter( tiles, wordlist, lett, k=1 )\n",
    "    clusters.append(ctmp[0])\n",
    "    scores.append(stmp[0])\n",
    "    tremain.append(ttmp[0])\n",
    "    \n",
    "    tiles = ttmp[0]\n",
    "    wordlist = cull_wordlist(wordlist, tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 w words\n",
      "21 v words\n"
     ]
    }
   ],
   "source": [
    "# gather the top cluster from each of four starting letters, proceeding recursively\n",
    "# and eliminating letters as we go\n",
    "letts = ['w','v']\n",
    "\n",
    "for lett in letts:\n",
    "    (ctmp, stmp, ttmp) = eliminate_letter( tiles, wordlist, lett, k=1 )\n",
    "    clusters.append(ctmp[0])\n",
    "    scores.append(stmp[0])\n",
    "    tremain.append(ttmp[0])\n",
    "    \n",
    "    tiles = ttmp[0]\n",
    "    wordlist = cull_wordlist(wordlist, tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['disjointednesses',\n",
       " 'prequalifying',\n",
       " 'neoorthodoxylographical',\n",
       " 'emblazoned',\n",
       " 'reembarkingcraft',\n",
       " 'avoweet',\n",
       " 'tavatu']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1184"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eeeeeeeeeaaaaaaaaaiiiiiiiooooooonnnnrrrrrrtttttlllluuuuddgggbbccmmppffhhvvwwyykxqz',\n",
       " 'eeeeeeeeaaaaaaaaiiiiiooooooonnnrrrrrtttttllluuuddggbbccmmpfhhvvwwykxz',\n",
       " 'eeeeeeeaaaaaaiiiioonnrrrttttluuudgbbcmmfvvwwkz',\n",
       " 'eeeeeaaaaaiiiionrrrttttuuugbcmfvvwwk',\n",
       " 'eeeaaaiiiotttuuuvvww',\n",
       " 'eaaiiittuuuvw',\n",
       " 'eiiiuuw']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tremain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2429 j words\n",
      "2519 q words\n",
      "4578 x words\n",
      "6627 z words\n",
      "11995 k words\n",
      "Wall time: 3min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create graphs to find the possible word clusters using\n",
    "# all the singleton letters (J,Q,X,Z,K)\n",
    "\n",
    "lett = 'j'\n",
    "(jwords,jscores) = getlettwords(WORDLIST,lett)\n",
    "print(len(jwords), lett, 'words')\n",
    "Gj = makegraph(jwords,lett)\n",
    "\n",
    "lett = 'q'\n",
    "(qwords,qscores) = getlettwords(WORDLIST,lett)\n",
    "print(len(qwords), lett, 'words')\n",
    "Gq = makegraph(qwords,lett)\n",
    "\n",
    "lett = 'x'\n",
    "(xwords,xscores) = getlettwords(WORDLIST,lett)\n",
    "print(len(xwords), lett, 'words')\n",
    "Gx = makegraph(xwords,lett)\n",
    "\n",
    "lett = 'z'\n",
    "(zwords,zscores) = getlettwords(WORDLIST,lett)\n",
    "print(len(zwords), lett, 'words')\n",
    "Gz = makegraph(zwords,lett)\n",
    "\n",
    "lett = 'k'\n",
    "(kwords,kscores) = getlettwords(WORDLIST,lett)\n",
    "print(len(kwords), lett, 'words')\n",
    "Gk = makegraph(kwords,lett)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# retrieve word clusters and their scores\n",
    "\n",
    "j_scores,j_words,j_unions = getbestcliques(Gj,'j')\n",
    "q_scores,q_words,q_unions = getbestcliques(Gq,'q')\n",
    "x_scores,x_words,x_unions = getbestcliques(Gx,'x')\n",
    "z_scores,z_words,z_unions = getbestcliques(Gz,'z')\n",
    "k_scores,k_words,k_unions = getbestcliques(Gk,'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmeta = 500\n",
    "tot_lettercount = np.array( [ [TILES.count(lett) for lett in ALPHABET] ] )\n",
    "j_lettercount   = np.array( [ [w.count(lett) for lett in ALPHABET] for w in j_unions[:Nmeta] ] )\n",
    "q_lettercount   = np.array( [ [w.count(lett) for lett in ALPHABET] for w in q_unions[:Nmeta] ] )\n",
    "x_lettercount   = np.array( [ [w.count(lett) for lett in ALPHABET] for w in x_unions[:Nmeta] ] )\n",
    "z_lettercount   = np.array( [ [w.count(lett) for lett in ALPHABET] for w in z_unions[:Nmeta] ] )\n",
    "k_lettercount   = np.array( [ [w.count(lett) for lett in ALPHABET] for w in k_unions[:Nmeta] ] )\n",
    "\n",
    "metawords = np.array([j_unions[:Nmeta] + q_unions[:Nmeta] + x_unions[:Nmeta] + z_unions[:Nmeta] + k_unions[:Nmeta]])\n",
    "metalettcounts = np.vstack( [j_lettercount, q_lettercount, x_lettercount, z_lettercount, k_lettercount] )\n",
    "metacounts = np.array([j_scores[:Nmeta] + q_scores[:Nmeta] + x_scores[:Nmeta] + z_scores[:Nmeta] + k_scores[:Nmeta]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "truemetacounts = np.array([[ stringscore(mw,WORDLIST) for mw in metawords[0] ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve generalized knapsack problem to find highest-scoring combinations of letters\n",
    "# that use the singleton tiles (J,Q,X,Z,K)\n",
    "m = Model(\"scrabble\")\n",
    "m.setParam( 'OutputFlag', False )\n",
    "\n",
    "M = metawords.shape[1]\n",
    "L = 26\n",
    "\n",
    "# Create variables (how many of each meta-word to use).\n",
    "w = m.addVars(M, vtype=GRB.INTEGER, lb=0, name=\"w\")\n",
    "\n",
    "# total number of words used and number of each letter used\n",
    "tot_score = quicksum(w[i]*truemetacounts[0,i] for i in range(M))\n",
    "letters_used = [ quicksum(metalettcounts[i,j]*w[i] for i in range(M)) for j in range(L) ]\n",
    "\n",
    "# Set objective (minimize number of words used)\n",
    "m.setObjective( tot_score, GRB.MAXIMIZE)\n",
    "\n",
    "# Constraint: must use as many letters as we have tiles of each sort\n",
    "m.addConstrs(  (letters_used[j] <= tot_lettercount[0,j] for j in range(L) ) )\n",
    "\n",
    "m.optimize()\n",
    "\n",
    "sol = [(ix,int(v.x),metawords[0,ix], truemetacounts[0,ix]) for ix,v in enumerate(m.getVars()) if v.x > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total score = 1129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(186, 1, 'hadjointworms', 168),\n",
       " (213, 1, 'prequalifying', 210),\n",
       " (511, 1, 'decarboxylated', 245),\n",
       " (632, 1, 'emblazoners', 209),\n",
       " (839, 1, 'outpolitickingfishers', 297)]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( \"total score =\", sum( item[3] for item in sol ) )\n",
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hadjointwormsprequalifyingdecarboxylatedemblazonersoutpolitickingfishers\n",
      "eeeeeeaaaaiioonnrttuudgvvw__\n"
     ]
    }
   ],
   "source": [
    "# assuming we will use the above list of words, what tiles are left over?\n",
    "tiles_used = ''.join( s[2] for s in sol )\n",
    "print(tiles_used)\n",
    "tmp = list(TILES)\n",
    "for z in tiles_used:\n",
    "    tmp.remove(z)\n",
    "tiles_remaining = ''.join(tmp)\n",
    "print(tiles_remaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word list contains 56548 words.\n"
     ]
    }
   ],
   "source": [
    "# what words are leftover from the wordlist using only these tiles?\n",
    "wordlist_remaining = cull_wordlist( WORDLIST, tiles_remaining )\n",
    "N_remaining = len(wordlist_remaining)\n",
    "print('The word list contains', N_remaining, 'words.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word list (blanks excluded) contains 3199 words.\n"
     ]
    }
   ],
   "source": [
    "# what words are leftover from the wordlist using only these tiles?\n",
    "wordlist_remaining_noblanks = cull_wordlist( WORDLIST, tiles_remaining[:-2] )\n",
    "N_remaining_noblanks = len(wordlist_remaining_noblanks)\n",
    "scores_remaining_noblanks = [ wordscore(w) for w in wordlist_remaining_noblanks ]\n",
    "print('The word list (blanks excluded) contains', N_remaining_noblanks, 'words.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'd', 'e', 'g', 'i', 'n', 'o', 'r', 't', 'u', 'v', 'w']\n",
      "[4, 1, 6, 1, 2, 2, 2, 1, 2, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "# now we must figure out what to do with the remaining letters.\n",
    "\n",
    "# find which letters are present and how many of each we have\n",
    "lett_present = [ lett for lett in ALPHABET if lett in tiles_remaining ]\n",
    "lett_counts_remaining = [ tiles_remaining.count(lett) for lett in lett_present ]\n",
    "print(lett_present)\n",
    "print(lett_counts_remaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# let's do the best we can using the single W:\n",
    "# create graphs to find the possible word clusters using W\n",
    "\n",
    "lett = 'w'\n",
    "(wwords,wscores) = getlettwords(wordlist_remaining_noblanks,lett)\n",
    "print(len(wwords), lett, 'words')\n",
    "Gw = makegraph(wwords,lett)\n",
    "w_scores,w_words,w_unions = getbestcliques(Gw,'w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### WORKING ON THIS ! ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uoadnationieeeeaavrvtwgeue\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "Z = np.array( [ v.x for ix,v in enumerate(mod.getVars()) if ix < d*p ] ).reshape((d,p))\n",
    "winstr = ''.join( [ [lett_present[ix] for ix,z in enumerate(Z[:,j]) if z][0] for j in range(p) ] )\n",
    "print(winstr)\n",
    "print(stringscore(winstr,wordlist_remaining_noblanks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 1 0 0 0]]\n",
      "[[0 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "z = np.array( [[1,0,0,0,1,0],[0,1,0,0,0,0],[0,0,0,1,0,1],[0,0,1,0,0,0]] )\n",
    "t = np.array( [[0,1],[0,0],[1,0],[0,0]] )\n",
    "print(z)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 2, 0]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j=0\n",
    "[ np.sum( z[:,j:j+2] * t ) for j in range(0,5) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_roller_wordlist = [ s[2] for s in sol ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prequalifyingemblazonershadjointwormsoutpolitickingfishersdecarboxylated\n",
      "1141\n"
     ]
    }
   ],
   "source": [
    "bestss = ''\n",
    "bestsc = 0\n",
    "for ss in itertools.permutations(high_roller_wordlist):\n",
    "    sss = ''.join(ss)\n",
    "    ssc = stringscore(sss)\n",
    "    if ssc > bestsc:\n",
    "        bestsc = ssc\n",
    "        bestss = sss\n",
    "print(bestss)\n",
    "print(bestsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eeeaaaaaiiiiiirttllubpvw__'"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remaining letters after high-rolling words used\n",
    "lett_remain = list(letterlist)\n",
    "for z in high_rollers:\n",
    "    lett_remain.remove(z)\n",
    "\n",
    "''.join(lett_remain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find words that will never be usable because there does not exist enough of the right letters\n",
    "remain_impossible_words = []\n",
    "remain_lettercount = np.array( [ [lett_remain.count(lett) for lett in alphabet] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33107"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(N):\n",
    "    if sum( [j for j in remain_lettercount[0]-wordlist_lettercount[i] if j <= 0] ) < -2:\n",
    "        remain_impossible_words.append( wordlist[i] )\n",
    "remain_wordlist = list( set(wordlist) - set(remain_impossible_words) )\n",
    "\n",
    "len(remain_wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rteoustnsrgiuaofamodcanpensvvtniwljeylodexrqidtgulboiaaedfargoihzncyopiioleieaubhremntsatkweareeei\n",
      "182\n",
      "rteoustnsrgiuaofamodcanpensvvtniwljeylodexrqidtgulboiaaedfargoihzncyopiioleieaubhremntsatkweareeze\n",
      "182\n",
      "rteoustnsrgiuaofamodcanpensvvtniwljeylodexrqidtgulboiaaedfargoihzncyopiioleieaubhremntsatkweareezz\n",
      "182\n",
      "rteoustnsrgiuaofamodcanpensvvtniwljeylodexrqidtgulboiaaedfargoihzncyopiioleieaubhremntsatkweareezz\n",
      "182\n",
      "rteoustnsrgiuaofamodcanpensvvtniwljeylodexrqidtgulboiaaedfargoihzncyopiioleieaubhremntsatkweareezz\n",
      "182\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "random.seed(0)\n",
    "s = TILES[:-2]\n",
    "n = len(s)\n",
    "ss = ''.join(random.sample(s,n))\n",
    "\n",
    "for j in range(5):\n",
    "    print(ss)\n",
    "    print(stringscore(ss,WORDLIST))\n",
    "    swaps = [ stringscore( ss[:i] + s[i+1:] + ss[i], WORDLIST) for i in range(n) ]\n",
    "    ix = np.argmax(swaps)\n",
    "    ss = ss[:ix] + s[ix+1:] + ss[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ovoearnwauitedeeugiaeatven\n",
      "42\n",
      "ovoearnwauitedeeugiaeatvwe\n",
      "45\n",
      "ovoearnwauitedeeugiaeatvwe\n",
      "45\n",
      "ovoearnwauitedeeugiaeatvwe\n",
      "45\n",
      "ovoearnwauitedeeugiaeatvwe\n",
      "45\n",
      "ovoearnwauitedeeugiaeatvwe\n",
      "45\n",
      "ovoearnwauitedeeugiaeatvwe\n",
      "45\n",
      "ovoearnwauitedeeugiaeatvwe\n",
      "45\n",
      "ovoearnwauitedeeugiaeatvwe\n",
      "45\n",
      "ovoearnwauitedeeugiaeatvwe\n",
      "45\n",
      "Wall time: 249 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "random.seed(0)\n",
    "s = tiles_remaining[:-2]\n",
    "n = len(s)\n",
    "ss = ''.join(random.sample(s,n))\n",
    "\n",
    "for j in range(10):\n",
    "    print(ss)\n",
    "    print(stringscore(ss,wordlist_remaining_noblanks))\n",
    "    swaps = [ stringscore( ss[:i] + s[i+1:] + ss[i], wordlist_remaining_noblanks) for i in range(n) ]\n",
    "    ix = np.argmax(swaps)\n",
    "    ss = ss[:ix] + s[ix+1:] + ss[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.4 ms ± 9.09 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit stringscore('raulasrakvqhncd_epoegecitiofrpaelilhsaoatjayabnatburzitsiwgrerooxgfdnesoivilnmdnuyomteeiwtnoeueeied', WORDLIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.2 ms ± 3.39 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit stringscore_filledblanks('raulasrakvqhncdEepoegecitiofrpaelilhsaoatjayabnatburzitsiwgrerooxgfdnesoivilnmdnuyomteeiwtnoeueeied', WORDLIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.53 s ± 123 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit stringscore_bestblanks('raulasrakvqhncd_epoegecitiofrpaelilhsaoatjayabnatburzitsiwgrerooxgfdnesoivilnmdnuyomteeiwtnoeueeied', WORDLIST)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
